# nondiffer-newton
Implement Newton optimization algorithm for non-differentiable functions using numerical differentiation

TODO:
- [ ] - implement algorithm
- [ ] - write tests (abs, trigonometrical etc, plot to check in wolfram alpha OR find function to work with nondif in scipy etc)
  - [ ] - gradient, hessian with implicit for differ functions
- [ ] - log output from function to files etc (gradient, hessian, newton methid steps AND compare to scipy.optimize for Newton for differ function AND try to find smth for nondiffer to compare how BIG is error)
- [ ] - convergence type (quaratical, linear?? should WORK the right way) 
- [ ] - try function of 1, 2, 3, 4, 5 variables AND different types (abs, trigon, quadratic, log, linear etc)
- [ ] - learn ALL theory about method and num differentiation (watch some lecture) AND make some notes

[Reference for numerical diff](https://rh8liuqy.github.io/Finite_Difference.html)
